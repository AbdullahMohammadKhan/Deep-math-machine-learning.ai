{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.framework import graph_util\n",
    "import numpy as np\n",
    "from IPython.display import Image,display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = '/home/mady/Desktop/Deep-math-machine-learning.ai/Meetups_Notebooks/Neural_Network_End2End/model_outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = mnist.train.images\n",
    "train_Y = mnist.train.labels\n",
    "test_X = mnist.test.images\n",
    "test_Y = mnist.test.labels\n",
    "\n",
    "# train_X = train_X.reshape(-1,28,28,1) #reshape as images\n",
    "# test_X = test_X.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training images shape (no of images, size of an image)\")\n",
    "print(train_X.shape,train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_single_image(image):\n",
    "    image= np.squeeze(image.reshape(28,28,1),axis=2)\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "visual_single_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mnist(images):\n",
    "    dim = images.shape[0]\n",
    "    n_image_rows = int(np.ceil(np.sqrt(dim)))\n",
    "    n_image_cols = int(np.ceil(dim * 1.0/n_image_rows))\n",
    "    gs = gridspec.GridSpec(n_image_rows,n_image_cols,top=1., bottom=0., right=1., left=0., hspace=0., wspace=0.)\n",
    "    \n",
    "    for g,count in zip(gs,range(int(dim))):\n",
    "        ax = plt.subplot(g)\n",
    "        ax.imshow(images[count,:].reshape((28,28)))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Training Images\")\n",
    "visualize_mnist(train_X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visulization is done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "no_hidden_neurons = 625\n",
    "no_classes = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None,input_size],name = \"Inputs\")# 784 featuress\n",
    "Y = tf.placeholder(\"float\", [None,no_classes]) # 10 classes\n",
    "\n",
    "W_H1 = tf.Variable(tf.random_normal([input_size,no_hidden_neurons], stddev=0.01)) #784 * 625\n",
    "W_H2 = tf.Variable(tf.random_normal([no_hidden_neurons,no_hidden_neurons],stddev = 0.01)) # 625*625\n",
    "W_O = tf.Variable(tf.random_normal([no_hidden_neurons,no_classes], stddev=0.01))  # 625*10\n",
    "\n",
    "def model(X, W_H1, W_H2, W_O):\n",
    "        h1 = tf.nn.relu(tf.matmul(X, W_H1))\n",
    "        h2 = tf.nn.relu(tf.matmul(h1,W_H2))\n",
    "        return tf.matmul(h2,W_O)\n",
    "    \n",
    "display(Image(\"images/model.jpg\",width=350,height=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = input_size*no_hidden_neurons + no_hidden_neurons*no_hidden_neurons + no_hidden_neurons* no_classes\n",
    "print(\"total no of weights are\",total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_logits = model(X, W_H1, W_H2, W_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_output_logits, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(\"images/instagram_notes.jpg\",width=700,height=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(0.05).minimize(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_outputs_Y = tf.argmax(model_output_logits, 1,name = \"Argmax\") # at predict time, evaluate the argmax\n",
    "# cast = tf.cast(predict_outputs_Y,tf.int32,name= \"cast\")\n",
    "predict_softmaxs_Y = tf.nn.softmax(model_output_logits, 1,name =\"Softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy (inputs,labels,sess):\n",
    "    return np.mean(np.argmax(labels, axis=1) == sess.run(predict_outputs_Y, feed_dict={X: inputs}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onehot(targets):\n",
    "    return np.eye(no_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_model(sess,path,model_name):\n",
    "\n",
    "    tf.train.write_graph(sess.graph_def, '.', path+model_name+'.pbtxt')\n",
    "    print(\"model protobuf is stored successfully!\")\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, path+model_name)\n",
    "    print(\"model checkpoint is saved successfully!\")\n",
    "\n",
    "\n",
    "def freeze_tf_model(path,model_name):\n",
    "\n",
    "    input_graph_path = path+model_name+'.pbtxt'\n",
    "    checkpoint_path = path+model_name\n",
    "    input_saver_def_path = \"\"\n",
    "    input_binary = False\n",
    "    output_node_names = \"Argmax\"\n",
    "    restore_op_name = \"save/restore_all\"\n",
    "    filename_tensor_name = \"save/Const:0\"\n",
    "    output_frozen_graph_name = path+'frozen_'+model_name+'.pb'\n",
    "    clear_devices = True\n",
    "\n",
    "    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                              input_binary, checkpoint_path, output_node_names,\n",
    "                              restore_op_name, filename_tensor_name,\n",
    "                              output_frozen_graph_name, clear_devices, \"\")\n",
    "    \n",
    "    print(\"model is freezed successfully!\")\n",
    "    \n",
    "def convert_to_tflite():\n",
    "    converter = tf.contrib.lite.TocoConverter.from_frozen_graph(path+'frozen_mnist.pb', ['Inputs'], ['Argmax'])\n",
    "    tflite_model = converter.convert()\n",
    "    open(path+\"mnist.tflite\", \"wb\").write(tflite_model)\n",
    "    print(\"Model is written as tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = convert_to_onehot(train_Y)\n",
    "test_Y_one_hot = convert_to_onehot(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "epoch_cost = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #to initialize all the variables\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        total_batch_cost = 0\n",
    "        \n",
    "        for start, end in zip(range(0, len(train_X), 128), range(128, len(train_X)+1, 128)):\n",
    "            feed_dict = {X : train_X[start:end] , Y : train_Y_one_hot[start:end]}\n",
    "            _,batch_cost = sess.run([optimizer,total_cost],feed_dict=feed_dict)\n",
    "            total_batch_cost += batch_cost\n",
    "            \n",
    "        epoch_cost.append(total_batch_cost)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print()\n",
    "            train_data_accuracy = get_accuracy(train_X,train_Y_one_hot,sess)\n",
    "            test_data_accuracy = get_accuracy(test_X,test_Y_one_hot,sess)\n",
    "            print(\"epoch : {}\\n train accuracy : {}\\n test accuracy : {} \" .format(epoch, train_data_accuracy,test_data_accuracy))\n",
    "            \n",
    "    print()\n",
    "    print(\"Training is done\")\n",
    "    test_predictions_Y = sess.run(predict_outputs_Y,feed_dict={X:test_X})\n",
    "    test_predictions_softmax_Y = sess.run(predict_softmaxs_Y,feed_dict={X:test_X})\n",
    "\n",
    "    save_tf_model(sess,path,\"mnist\")\n",
    "    freeze_tf_model(path,\"mnist\")\n",
    "    convert_to_tflite()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visulize_cost(epoch_cost):\n",
    "    indices = [i for i in range(len(epoch_cost))]\n",
    "    plt.plot(indices,epoch_cost,marker=\"o\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.xlim(0, len(indices))\n",
    "    plt.show()\n",
    "visulize_cost(epoch_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Images\")\n",
    "visualize_mnist(test_X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_Y[:100] == test_Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_softmax_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction from .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "graph = load_graph(path+'frozen_mnist.pb')\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)\n",
    "x = graph.get_tensor_by_name('import/Inputs:0')\n",
    "y = graph.get_tensor_by_name('import/Argmax:0')\n",
    "\n",
    "image = train_X[2]\n",
    "visual_single_image(image)\n",
    "image = np.expand_dims(image,axis=0)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run([y],feed_dict={x:image})\n",
    "    print(\"The Number is \",output[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
