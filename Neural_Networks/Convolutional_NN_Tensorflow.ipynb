{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train,Y_train),(X_test,Y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  43  50 ..., 158 152 148]\n",
      "  [ 16   0  18 ..., 123 119 122]\n",
      "  [ 25  16  49 ..., 118 120 109]\n",
      "  ..., \n",
      "  [208 201 198 ..., 160  56  53]\n",
      "  [180 173 186 ..., 184  97  83]\n",
      "  [177 168 179 ..., 216 151 123]]\n",
      "\n",
      " [[ 62  46  48 ..., 132 125 124]\n",
      "  [ 20   0   8 ...,  88  83  87]\n",
      "  [ 24   7  27 ...,  84  84  73]\n",
      "  ..., \n",
      "  [170 153 161 ..., 133  31  34]\n",
      "  [139 123 144 ..., 148  62  53]\n",
      "  [144 129 142 ..., 184 118  92]]\n",
      "\n",
      " [[ 63  45  43 ..., 108 102 103]\n",
      "  [ 20   0   0 ...,  55  50  57]\n",
      "  [ 21   0   8 ...,  50  50  42]\n",
      "  ..., \n",
      "  [ 96  34  26 ...,  70   7  20]\n",
      "  [ 96  42  30 ...,  94  34  34]\n",
      "  [116  94  87 ..., 140  84  72]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.23137255,  0.16862745,  0.19607843, ...,  0.61960784,\n",
       "          0.59607843,  0.58039216],\n",
       "        [ 0.0627451 ,  0.        ,  0.07058824, ...,  0.48235294,\n",
       "          0.46666667,  0.47843137],\n",
       "        [ 0.09803922,  0.0627451 ,  0.19215686, ...,  0.4627451 ,\n",
       "          0.47058824,  0.42745098],\n",
       "        ..., \n",
       "        [ 0.81568627,  0.78823529,  0.77647059, ...,  0.62745098,\n",
       "          0.21960784,  0.20784314],\n",
       "        [ 0.70588235,  0.67843137,  0.72941176, ...,  0.72156863,\n",
       "          0.38039216,  0.3254902 ],\n",
       "        [ 0.69411765,  0.65882353,  0.70196078, ...,  0.84705882,\n",
       "          0.59215686,  0.48235294]],\n",
       "\n",
       "       [[ 0.24313725,  0.18039216,  0.18823529, ...,  0.51764706,\n",
       "          0.49019608,  0.48627451],\n",
       "        [ 0.07843137,  0.        ,  0.03137255, ...,  0.34509804,\n",
       "          0.3254902 ,  0.34117647],\n",
       "        [ 0.09411765,  0.02745098,  0.10588235, ...,  0.32941176,\n",
       "          0.32941176,  0.28627451],\n",
       "        ..., \n",
       "        [ 0.66666667,  0.6       ,  0.63137255, ...,  0.52156863,\n",
       "          0.12156863,  0.13333333],\n",
       "        [ 0.54509804,  0.48235294,  0.56470588, ...,  0.58039216,\n",
       "          0.24313725,  0.20784314],\n",
       "        [ 0.56470588,  0.50588235,  0.55686275, ...,  0.72156863,\n",
       "          0.4627451 ,  0.36078431]],\n",
       "\n",
       "       [[ 0.24705882,  0.17647059,  0.16862745, ...,  0.42352941,\n",
       "          0.4       ,  0.40392157],\n",
       "        [ 0.07843137,  0.        ,  0.        , ...,  0.21568627,\n",
       "          0.19607843,  0.22352941],\n",
       "        [ 0.08235294,  0.        ,  0.03137255, ...,  0.19607843,\n",
       "          0.19607843,  0.16470588],\n",
       "        ..., \n",
       "        [ 0.37647059,  0.13333333,  0.10196078, ...,  0.2745098 ,\n",
       "          0.02745098,  0.07843137],\n",
       "        [ 0.37647059,  0.16470588,  0.11764706, ...,  0.36862745,\n",
       "          0.13333333,  0.13333333],\n",
       "        [ 0.45490196,  0.36862745,  0.34117647, ...,  0.54901961,\n",
       "          0.32941176,  0.28235294]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a one hot vector for label\n",
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train=np_utils.to_categorical(Y_train)\n",
    "Y_test=np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.placeholder(\"float\",[None,32,32,3]) # as our dataset\n",
    "Y = tf.placeholder(\"float\",[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "W_C1 = init_weights([3,3,3,32])# 3x3x3 conv, 32 outputs\n",
    "W_C2 = init_weights([3,3,32,64])# 3x3x32 conv, 64 outputs\n",
    "W_C3 = init_weights([3, 3, 64, 128])# 3x3x64 conv, 128 outputs\n",
    "\n",
    "W_FC = init_weights([128 * 4 * 4, 625]) # FC 128 * 4 * 4 inputs, 625 outputs\n",
    "W_O = init_weights([625, 10])         # FC 625 inputs, 10 outputs (labels)\n",
    "\n",
    "p_keep_conv = tf.placeholder(\"float\") #for dropouts as percentage\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, W_C1, W_C2, W_C3, W_FC, W_O, p_keep_conv,p_keep_hidden):\n",
    "    \n",
    "    C1 = tf.nn.relu(tf.nn.conv2d(X,W_C1,\n",
    "                                strides=[1,1,1,1], padding = \"SAME\")) \n",
    "    \n",
    "    P1 = tf.nn.max_pool(C1,ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1], padding = \"SAME\" ) # 1st pooling layer shape =(?,14,14,32)\n",
    "    \n",
    "    D1 = tf.nn.dropout(P1,p_keep_conv) # 1st dropout at conv\n",
    "    \n",
    "    C2 = tf.nn.relu(tf.nn.conv2d(D1,W_C2,\n",
    "                                strides=[1,1,1,1], padding = \"SAME\")) # 2nd convoultion layer shape=(?, 14, 14, 62)\n",
    "    \n",
    "    P2 = tf.nn.max_pool(C2,ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1], padding = \"SAME\" ) # 2nd pooling layer shape =(?,7,7,64)\n",
    "    \n",
    "    D2 = tf.nn.dropout(P2,p_keep_conv) # 2nd dropout at conv\n",
    "    \n",
    "    \n",
    "    C3 = tf.nn.relu(tf.nn.conv2d(D2,W_C3,\n",
    "                                strides=[1,1,1,1], padding = \"SAME\")) # 3rd convoultion layer shape=(?, 7, 7, 128)\n",
    "    \n",
    "    P3 = tf.nn.max_pool(C3,ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1], padding = \"SAME\" ) # 3rd pooling layer shape =(?,4,4,128)\n",
    "    \n",
    "    P3 = tf.reshape(P3, [-1, W_FC.get_shape().as_list()[0]])    # reshape to (?, 2048)\n",
    "    D3 = tf.nn.dropout(P3, p_keep_conv) # 3rd dropout at conv\n",
    "    \n",
    "    FC = tf.nn.relu(tf.matmul(D3,W_FC))\n",
    "    FC = tf.nn.dropout(FC, p_keep_hidden) #droput at fc\n",
    "    \n",
    "    output = tf.matmul(FC,W_O)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model(X, W_C1, W_C2, W_C3, W_FC, W_O, p_keep_conv,p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y_pred ,labels = Y))\n",
    " # compute mean cross entropy (softmax is applied internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(Y_pred, 1) # at predict time, evaluate the argmax of the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshape as images according to tf \n",
    "X_train = X_train.reshape(-1,32,32,3) \n",
    "X_test = X_test.reshape(-1,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 and accuracy : 0.2622\n",
      "testing labels for test data\n",
      "[3 8 8 ..., 3 1 7]\n",
      "epoch : 10 and accuracy : 0.5798\n",
      "testing labels for test data\n",
      "[3 8 8 ..., 5 1 7]\n",
      "epoch : 20 and accuracy : 0.6304\n",
      "testing labels for test data\n",
      "[3 8 8 ..., 5 1 7]\n",
      "epoch : 30 and accuracy : 0.6497\n",
      "testing labels for test data\n",
      "[6 8 8 ..., 5 1 7]\n",
      "epoch : 40 and accuracy : 0.6497\n",
      "testing labels for test data\n",
      "[3 8 8 ..., 5 1 7]\n",
      "Final accuracy : 0.6332\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for start, end in zip(range(0, len(X_train), 128), range(128, len(X_train)+1, 128)): \n",
    "            sess.run(optimizer,feed_dict={X : X_train[start:end] , Y : Y_train[start:end],\n",
    "                                          p_keep_conv: 0.8, p_keep_hidden: 0.5})\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy= np.mean(np.argmax(Y_test, axis=1) == \n",
    "                              sess.run(predict_op, feed_dict={X: X_test, p_keep_conv: 1.0, p_keep_hidden: 1.0}))\n",
    "                              \n",
    "            print(\"epoch : {} and accuracy : {}\" .format(epoch, accuracy))\n",
    "            \n",
    "            print(\"testing labels for test data\")\n",
    "            print(sess.run(predict_op, feed_dict={X: X_test,p_keep_conv: 1.0, p_keep_hidden: 1.0}))\n",
    "            \n",
    "    print(\"Final accuracy : {}\" .format(np.mean(np.argmax(Y_test, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: X_test, p_keep_conv: 1.0, p_keep_hidden: 1.0}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
